import random
import xml.etree.ElementTree as ET
from xml.dom import minidom
import os
from datetime import datetime
from typing import List, Dict, Tuple, Set
import itertools


class XMLDataGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä XML —Ñ–∞–π–ª–æ–≤ –¥–ª—è DS/AHP-GDM"""

    def __init__(self, seed: int = None):

        if seed is not None:
            random.seed(seed)
        self.generated_files = []

    def generate_alternatives(self, n: int) -> List[str]:
        if n < 1:
            n = 1
        elif n > 100:
            n = 100

        return [f"A{i:03d}" for i in range(1, n + 1)]

    def generate_criteria(self, m: int) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è m –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤

        Args:
            m: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ (1-10)

        Returns:
            –°–ø–∏—Å–æ–∫ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
        """
        base_criteria = [
            "–ö–∞—á–µ—Å—Ç–≤–æ", "–°—Ç–æ–∏–º–æ—Å—Ç—å", "–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å", "–£–¥–æ–±—Å—Ç–≤–æ", "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
            "–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–≠–∫–æ–ª–æ–≥–∏—á–Ω–æ—Å—Ç—å", "–°—Ä–æ–∫ —Å–ª—É–∂–±—ã", "–ì–∞—Ä–∞–Ω—Ç–∏—è", "–ü–æ–¥–¥–µ—Ä–∂–∫–∞"
        ]

        if m <= len(base_criteria):
            return base_criteria[:m]
        else:
            return [f"–ö—Ä–∏—Ç–µ—Ä–∏–π_{i + 1}" for i in range(m)]

    def generate_expert_names(self, k: int) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω —ç–∫—Å–ø–µ—Ä—Ç–æ–≤

        Args:
            k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (1-10)

        Returns:
            –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        """
        base_names = ["–ò–≤–∞–Ω–æ–≤", "–ü–µ—Ç—Ä–æ–≤", "–°–∏–¥–æ—Ä–æ–≤", "–ö—É–∑–Ω–µ—Ü–æ–≤", "–°–º–∏—Ä–Ω–æ–≤",
                      "–ü–æ–ø–æ–≤", "–õ–µ–±–µ–¥–µ–≤", "–ö–æ–∑–ª–æ–≤", "–ù–æ–≤–∏–∫–æ–≤", "–ú–æ—Ä–æ–∑–æ–≤"]

        if k <= len(base_names):
            return base_names[:k]
        else:
            return [f"–≠–∫—Å–ø–µ—Ä—Ç_{i + 1}" for i in range(k)]

    def generate_expert_weights(self, k: int,
                                distribution: str = "uniform") -> List[float]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–µ—Å–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤

        Args:
            k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
            distribution: —Ç–∏–ø —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è ('uniform', 'decreasing', 'equal')

        Returns:
            –°–ø–∏—Å–æ–∫ –≤–µ—Å–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        """
        if distribution == "equal":
            return [1.0] * k
        elif distribution == "decreasing":
            # –í–µ—Å–∞ —É–º–µ–Ω—å—à–∞—é—Ç—Å—è –æ—Ç 1.0
            weights = [1.0 - i * 0.8 / (k - 1) for i in range(k)]
            return [max(w, 0.1) for w in weights]  # –ú–∏–Ω–∏–º—É–º 0.1
        else:  # uniform
            return [round(random.uniform(0.3, 1.0), 2) for _ in range(k)]

    def generate_cpvs(self, criteria: List[str]) -> Dict[str, float]:
        """
        –ê–±—Å–æ–ª—é—Ç–Ω–æ –Ω–∞–¥–µ–∂–Ω—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ CPV

        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞, –∑–∞—Ç–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç
        """
        n = len(criteria)

        if n == 1:
            return {criteria[0]: 1.0}

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞ –æ—Ç 1 –¥–æ 10
        int_values = [random.randint(1, 10) for _ in range(n)]

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ —Å—É–º–º–µ 1.0
        total = sum(int_values)
        cpvs = {}

        for i, criterion in enumerate(criteria):
            cpv = int_values[i] / total

            # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ 3 –∑–Ω–∞–∫–æ–≤
            cpvs[criterion] = round(cpv, 3)

        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ–π —Å—É–º–º—ã
        current_sum = sum(cpvs.values())
        if abs(current_sum - 1.0) > 0.0001:
            last_criterion = criteria[-1]
            cpvs[last_criterion] = round(cpvs[last_criterion] + (1.0 - current_sum), 3)

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        final_sum = sum(cpvs.values())
        if abs(final_sum - 1.0) > 0.001:
            # –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞
            equal_value = round(1.0 / n, 3)
            cpvs = {c: equal_value for c in criteria}

            # –ü–æ–¥–≥–æ–Ω—è–µ–º —Å—É–º–º—É
            adjusted_sum = sum(cpvs.values())
            if adjusted_sum != 1.0:
                cpvs[criteria[0]] = round(cpvs[criteria[0]] + (1.0 - adjusted_sum), 3)

        return cpvs

    def generate_preferences_for_expert(self, alternatives: List[str],
                                        criteria: List[str],
                                        min_groups_per_criterion: int = 2,
                                        max_groups_per_criterion: int = 5) -> Dict[str, Dict[str, int]]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –¥–ª—è –æ–¥–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞

        –í–∞–∂–Ω–æ: –ö–∞–∂–¥–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –¥–æ–ª–∂–Ω–∞ –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è —Ä–æ–≤–Ω–æ 1 —Ä–∞–∑ –≤ –∫–∞–∂–¥–æ–º –∫—Ä–∏—Ç–µ—Ä–∏–∏
        """
        preferences = {}
        n = len(alternatives)

        for criterion in criteria:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ –¥–ª—è –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏—è
            shuffled_alts = alternatives.copy()
            random.shuffle(shuffled_alts)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä—É–ø–ø –¥–ª—è —ç—Ç–æ–≥–æ –∫—Ä–∏—Ç–µ—Ä–∏—è
            num_groups = random.randint(min_groups_per_criterion,
                                        min(max_groups_per_criterion, n // 2))

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –ø–æ –≥—Ä—É–ø–ø–∞–º
            groups = []
            remaining_alts = shuffled_alts.copy()

            # –°–æ–∑–¥–∞–µ–º –≥—Ä—É–ø–ø—ã
            for i in range(num_groups - 1):
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã (–º–∏–Ω–∏–º—É–º 1, –º–∞–∫—Å–∏–º—É–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è/2)
                max_size = max(1, len(remaining_alts) - (num_groups - i - 1))
                group_size = random.randint(1, min(3, max_size))

                # –ë–µ—Ä–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è –≥—Ä—É–ø–ø—ã
                group = remaining_alts[:group_size]
                groups.append(group)
                remaining_alts = remaining_alts[group_size:]

            # –ü–æ—Å–ª–µ–¥–Ω—è—è –≥—Ä—É–ø–ø–∞ –ø–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
            if remaining_alts:
                groups.append(remaining_alts)
            else:
                # –ï—Å–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å, –¥–æ–±–∞–≤–ª—è–µ–º –æ–¥–Ω—É –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≥—Ä—É–ø–ø
                if groups:
                    group_to_split = random.choice(groups)
                    if len(group_to_split) > 1:
                        split_point = random.randint(1, len(group_to_split) - 1)
                        new_group = group_to_split[split_point:]
                        group_to_split = group_to_split[:split_point]
                        groups.append(new_group)

            # –ù–∞–∑–Ω–∞—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –≥—Ä—É–ø–ø–∞–º (—à–∫–∞–ª–∞ 1-7)
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—ã –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ (–±–æ–ª—å—à–∏–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª—É—á–∞—é—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è)
            groups_sorted = sorted(groups, key=len, reverse=True)

            criterion_preferences = {}
            used_preferences = set()

            for i, group in enumerate(groups_sorted):
                # –í—ã—á–∏—Å–ª—è–µ–º –±–∞–∑–æ–≤–æ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ (–æ—Ç 7 –¥–æ 1)
                base_pref = 7 - i
                if base_pref < 1:
                    base_pref = 1

                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é —Å–ª—É—á–∞–π–Ω—É—é –≤–∞—Ä–∏–∞—Ü–∏—é
                pref = base_pref + random.randint(-1, 1)
                pref = max(1, min(7, pref))

                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã
                while pref in used_preferences:
                    pref += random.choice([-1, 1])
                    pref = max(1, min(7, pref))

                used_preferences.add(pref)

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—É –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                group_str = ",".join(sorted(group))
                criterion_preferences[group_str] = pref

            preferences[criterion] = criterion_preferences

            # –ü–†–û–í–ï–†–ö–ê: –∫–∞–∂–¥–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –¥–æ–ª–∂–Ω–∞ –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è —Ä–æ–≤–Ω–æ 1 —Ä–∞–∑
            all_alts_in_groups = []
            for group in groups:
                all_alts_in_groups.extend(group)

            if sorted(all_alts_in_groups) != sorted(alternatives):
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞: –Ω–µ –≤—Å–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã —É—á—Ç–µ–Ω—ã –≤ –∫—Ä–∏—Ç–µ—Ä–∏–∏ {criterion}")
                print(f"  –£—á—Ç–µ–Ω–æ: {len(all_alts_in_groups)} –∏–∑ {len(alternatives)}")
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º: –Ω–∞—Ö–æ–¥–∏–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
                missing = set(alternatives) - set(all_alts_in_groups)
                duplicates = set([x for x in all_alts_in_groups if all_alts_in_groups.count(x) > 1])

                if missing:
                    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω—ã: {missing}")
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –≤ —Å–ª—É—á–∞–π–Ω—É—é –≥—Ä—É–ø–ø—É
                    for alt in missing:
                        random.choice(groups).append(alt)

                if duplicates:
                    print(f"  –î—É–±–ª–∏–∫–∞—Ç—ã: {duplicates}")

        return preferences

    def validate_preferences(self, preferences: Dict[str, Dict[str, int]],
                             alternatives: List[str]) -> bool:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π

        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –∫–∞–∂–¥–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Ä–æ–≤–Ω–æ 1 —Ä–∞–∑ –≤ –∫–∞–∂–¥–æ–º –∫—Ä–∏—Ç–µ—Ä–∏–∏
        """
        for criterion, groups in preferences.items():
            all_alts_in_criterion = []

            for group_str in groups.keys():
                group_alts = [alt.strip() for alt in group_str.split(',')]
                all_alts_in_criterion.extend(group_alts)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            if len(all_alts_in_criterion) != len(alternatives):
                print(f"‚ùå –ö—Ä–∏—Ç–µ—Ä–∏–π {criterion}: {len(all_alts_in_criterion)} –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ –≤–º–µ—Å—Ç–æ {len(alternatives)}")
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å
            if len(set(all_alts_in_criterion)) != len(alternatives):
                duplicates = [x for x in all_alts_in_criterion if all_alts_in_criterion.count(x) > 1]
                print(f"‚ùå –ö—Ä–∏—Ç–µ—Ä–∏–π {criterion}: –¥—É–±–ª–∏–∫–∞—Ç—ã {duplicates}")
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            missing = set(alternatives) - set(all_alts_in_criterion)
            if missing:
                print(f"‚ùå –ö—Ä–∏—Ç–µ—Ä–∏–π {criterion}: –ø—Ä–æ–ø—É—â–µ–Ω—ã {missing}")
                return False

        return True

    def generate_dataset(self,
                         n_alternatives: int = 10,
                         m_criteria: int = 3,
                         k_experts: int = 4,
                         weight_distribution: str = "uniform",
                         output_dir: str = "generated_xml") -> Dict:
        print("\n" + "=" * 70)
        print("–ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–ù–ù–´–• –î–õ–Ø DS/AHP-GDM")
        print("=" * 70)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
        n_alternatives = max(1, min(100, n_alternatives))
        m_criteria = max(1, min(10, m_criteria))
        k_experts = max(1, min(10, k_experts))

        print(f"\n –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:")
        print(f"  ‚Ä¢ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤: {n_alternatives}")
        print(f"  ‚Ä¢ –ö—Ä–∏—Ç–µ—Ä–∏–µ–≤: {m_criteria}")
        print(f"  ‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç–æ–≤: {k_experts}")
        print(f"  ‚Ä¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤: {weight_distribution}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        alternatives = self.generate_alternatives(n_alternatives)
        criteria = self.generate_criteria(m_criteria)
        expert_names = self.generate_expert_names(k_experts)
        expert_weights = self.generate_expert_weights(k_experts, weight_distribution)

        print(f"\n‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –±–∞–∑–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:")
        print(f"  –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã: {alternatives[:5]}{'...' if len(alternatives) > 5 else ''}")
        print(f"  –ö—Ä–∏—Ç–µ—Ä–∏–∏: {criteria}")
        print(f"  –≠–∫—Å–ø–µ—Ä—Ç—ã: {expert_names}")
        print(f"  –í–µ—Å–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {expert_weights}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
        experts_data = {}

        print(f"\nüîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤...")

        for i, expert_name in enumerate(expert_names):
            print(f"  –≠–∫—Å–ø–µ—Ä—Ç {i + 1}: {expert_name} (–≤–µ—Å: {expert_weights[i]})")

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º CPV
            cpvs = self.generate_cpvs(criteria)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
            preferences = self.generate_preferences_for_expert(
                alternatives, criteria,
                min_groups_per_criterion=2,
                max_groups_per_criterion=min(5, n_alternatives // 2)
            )

            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
            if not self.validate_preferences(preferences, alternatives):
                print(f"  ‚ö†Ô∏è  –ü—Ä–æ–±–ª–µ–º—ã —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–∞ {expert_name}")
                print(f"   –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ...")
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
                preferences = self.fix_preferences(preferences, alternatives, criteria)

            experts_data[expert_name] = {
                'weight': expert_weights[i],
                'cpvs': cpvs,
                'preferences': preferences
            }

            # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            total_groups = sum(len(groups) for groups in preferences.values())
            print(f"    ‚Ä¢ CPV: {cpvs}")
            print(f"    ‚Ä¢ –ì—Ä—É–ø–ø –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π: {total_groups}")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –Ω–∞–±–æ—Ä
        dataset = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'parameters': {
                    'n_alternatives': n_alternatives,
                    'm_criteria': m_criteria,
                    'k_experts': k_experts,
                    'weight_distribution': weight_distribution
                }
            },
            'alternatives': alternatives,
            'criteria': criteria,
            'experts': experts_data
        }

        # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        self.print_summary(dataset)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ XML
        xml_file = self.save_to_xml(dataset, output_dir)

        return dataset, xml_file

    def fix_preferences(self, preferences: Dict[str, Dict[str, int]],
                         alternatives: List[str],
                         criteria: List[str]) -> Dict[str, Dict[str, int]]:
        """
        –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π, —á—Ç–æ–±—ã –∫–∞–∂–¥–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –≤—Å—Ç—Ä–µ—á–∞–ª–∞—Å—å —Ä–æ–≤–Ω–æ 1 —Ä–∞–∑
        """
        fixed_preferences = {}

        for criterion in criteria:
            if criterion not in preferences:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ –∫—Ä–∏—Ç–µ—Ä–∏—è
                groups = []
                shuffled_alts = alternatives.copy()
                random.shuffle(shuffled_alts)

                # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ 2-5 –≥—Ä—É–ø–ø
                num_groups = random.randint(2, min(5, len(alternatives) // 2))

                for i in range(num_groups - 1):
                    group_size = random.randint(1, len(shuffled_alts) - (num_groups - i - 1))
                    group = shuffled_alts[:group_size]
                    groups.append(group)
                    shuffled_alts = shuffled_alts[group_size:]

                if shuffled_alts:
                    groups.append(shuffled_alts)

                # –ù–∞–∑–Ω–∞—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
                criterion_prefs = {}
                groups_sorted = sorted(groups, key=len, reverse=True)
                used_prefs = set()

                for i, group in enumerate(groups_sorted):
                    base_pref = 7 - i
                    if base_pref < 1:
                        base_pref = 1

                    pref = base_pref + random.randint(-1, 1)
                    pref = max(1, min(7, pref))

                    while pref in used_prefs:
                        pref += random.choice([-1, 1])
                        pref = max(1, min(7, pref))

                    used_prefs.add(pref)
                    group_str = ",".join(sorted(group))
                    criterion_prefs[group_str] = pref

                fixed_preferences[criterion] = criterion_prefs
            else:
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
                original_groups = list(preferences[criterion].keys())
                original_prefs = list(preferences[criterion].values())

                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –∏–∑ –≥—Ä—É–ø–ø
                all_alts = []
                for group_str in original_groups:
                    group_alts = [alt.strip() for alt in group_str.split(',')]
                    all_alts.extend(group_alts)

                # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–æ–±–ª–µ–º—ã
                alt_counts = {}
                for alt in all_alts:
                    alt_counts[alt] = alt_counts.get(alt, 0) + 1

                missing_alts = set(alternatives) - set(all_alts)
                duplicate_alts = {alt for alt, count in alt_counts.items() if count > 1}

                if not missing_alts and not duplicate_alts:
                    # –í—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ
                    fixed_preferences[criterion] = preferences[criterion]
                    continue

                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º: —Å–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                fixed_groups = []
                used_alts = set()

                for group_str in original_groups:
                    group_alts = [alt.strip() for alt in group_str.split(',')]
                    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                    unique_alts = []
                    for alt in group_alts:
                        if alt not in used_alts:
                            unique_alts.append(alt)
                            used_alts.add(alt)

                    if unique_alts:
                        fixed_groups.append(unique_alts)

                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
                for alt in missing_alts:
                    if alt not in used_alts:
                        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ª—É—á–∞–π–Ω—É—é –≥—Ä—É–ø–ø—É
                        if fixed_groups:
                            random.choice(fixed_groups).append(alt)
                            used_alts.add(alt)
                        else:
                            fixed_groups.append([alt])
                            used_alts.add(alt)

                # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
                fixed_prefs = {}
                groups_sorted = sorted(fixed_groups, key=len, reverse=True)

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
                for i, group in enumerate(groups_sorted):
                    group_str = ",".join(sorted(group))

                    if i < len(original_prefs):
                        pref = original_prefs[i]
                    else:
                        base_pref = 7 - i
                        if base_pref < 1:
                            base_pref = 1
                        pref = base_pref

                    fixed_prefs[group_str] = pref

                fixed_preferences[criterion] = fixed_prefs

        return fixed_preferences

    def print_summary(self, dataset: Dict):
        """–í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –ø–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º"""
        print("\n" + "=" * 70)
        print("–°–í–û–î–ö–ê –ü–û –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ù–´–ú –î–ê–ù–ù–´–ú")
        print("=" * 70)

        alternatives = dataset['alternatives']
        criteria = dataset['criteria']
        experts = dataset['experts']

        print(f"\n –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
        print(f"  ‚Ä¢ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤: {len(alternatives)}")
        print(f"  ‚Ä¢ –ö—Ä–∏—Ç–µ—Ä–∏–µ–≤: {len(criteria)}")
        print(f"  ‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç–æ–≤: {len(experts)}")

        print(f"\n –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏:")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
        all_valid = True

        for expert_name, expert_data in experts.items():
            print(f"\n –≠–∫—Å–ø–µ—Ä—Ç: {expert_name}")
            print(f"    ‚Ä¢ –í–µ—Å: {expert_data['weight']}")
            print(f"    ‚Ä¢ –°—É–º–º–∞ CPV: {sum(expert_data['cpvs'].values()):.3f}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
            preferences = expert_data['preferences']
            is_valid = self.validate_preferences(preferences, alternatives)

            if is_valid:
                print(f"    ‚Ä¢ ‚úÖ –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã")

                # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≥—Ä—É–ø–ø–∞–º
                total_groups = sum(len(groups) for groups in preferences.values())
                avg_group_size = sum(len(group_str.split(',')) for criterion_groups in preferences.values()
                                     for group_str in criterion_groups.keys()) / total_groups if total_groups > 0 else 0

                print(f"    ‚Ä¢ –ì—Ä—É–ø–ø: {total_groups}")
                print(f"    ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã: {avg_group_size:.1f}")
            else:
                print(f"    ‚Ä¢ ‚ùå –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞—Ç –æ—à–∏–±–∫–∏")
                all_valid = False

        if all_valid:
            print(f"\n –í–°–ï –î–ê–ù–ù–´–ï –ö–û–†–†–ï–ö–¢–ù–´!")
        else:
            print(f"\n‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –≤ –¥–∞–Ω–Ω—ã—Ö")

    def save_to_xml(self, dataset: Dict, output_dir: str = "generated_xml") -> str:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        os.makedirs(output_dir, exist_ok=True)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        n_alts = len(dataset['alternatives'])
        n_experts = len(dataset['experts'])
        filename = f"gdm_data_{n_alts}alt_{n_experts}exp_{timestamp}.xml"
        filepath = os.path.join(output_dir, filename)

        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ XML —Ñ–∞–π–ª: {filename}")

        # –°–æ–∑–¥–∞–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π —ç–ª–µ–º–µ–Ω—Ç
        root = ET.Element('ds_ahp_gdm_analysis')

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        comment = ET.Comment(' –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ XMLDataGenerator –¥–ª—è DS/AHP-GDM ')
        root.append(comment)

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = ET.SubElement(root, 'metadata')

        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        alts_elem = ET.SubElement(metadata, 'alternatives')
        alts_elem.text = ','.join(dataset['alternatives'])

        # –ö—Ä–∏—Ç–µ—Ä–∏–∏
        criteria_elem = ET.SubElement(metadata, 'criteria')
        criteria_elem.text = ','.join(dataset['criteria'])

        # –≠–∫—Å–ø–µ—Ä—Ç—ã
        experts_elem = ET.SubElement(metadata, 'experts')
        experts_elem.text = ','.join(dataset['experts'].keys())

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        gen_info = ET.SubElement(metadata, 'generation_info')
        gen_info.set('timestamp', dataset['metadata']['generated_at'])
        gen_info.set('n_alternatives', str(dataset['metadata']['parameters']['n_alternatives']))
        gen_info.set('n_criteria', str(dataset['metadata']['parameters']['m_criteria']))
        gen_info.set('n_experts', str(dataset['metadata']['parameters']['k_experts']))

        # –≠–∫—Å–ø–µ—Ä—Ç—ã
        experts_root = ET.SubElement(root, 'experts')

        for expert_name, expert_data in dataset['experts'].items():
            expert_elem = ET.SubElement(experts_root, 'expert')
            expert_elem.set('name', expert_name)
            expert_elem.set('weight', f"{expert_data['weight']:.2f}")

            # CPV
            cpvs_elem = ET.SubElement(expert_elem, 'cpvs')
            for criterion, cpv in expert_data['cpvs'].items():
                criterion_elem = ET.SubElement(cpvs_elem, 'criterion')
                criterion_elem.set('name', criterion)
                criterion_elem.text = f"{cpv:.3f}"

            # –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
            prefs_elem = ET.SubElement(expert_elem, 'preferences')
            for criterion, groups in expert_data['preferences'].items():
                criterion_elem = ET.SubElement(prefs_elem, 'criterion')
                criterion_elem.set('name', criterion)

                for group_str, preference in groups.items():
                    group_elem = ET.SubElement(criterion_elem, 'group')
                    group_elem.set('preference', str(preference))
                    group_elem.text = group_str

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º XML
        xml_string = ET.tostring(root, encoding='unicode', method='xml')

        # –î–æ–±–∞–≤–ª—è–µ–º XML –¥–µ–∫–ª–∞—Ä–∞—Ü–∏—é
        xml_declaration = '<?xml version="1.0" encoding="UTF-8"?>\n'
        full_xml = xml_declaration + xml_string

        # –î–µ–ª–∞–µ–º –∫—Ä–∞—Å–∏–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        dom = minidom.parseString(full_xml)
        pretty_xml = dom.toprettyxml(indent="  ")

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        lines = [line for line in pretty_xml.split('\n') if line.strip()]
        formatted_xml = '\n'.join(lines)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        with open(filepath, 'w', encoding='utf-8', newline='\n') as f:
            f.write(formatted_xml)

        print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath}")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.generated_files.append(filepath)

        return filepath
