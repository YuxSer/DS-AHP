import random
import xml.etree.ElementTree as ET
from xml.dom import minidom
import os
from datetime import datetime
from typing import List, Dict, Tuple, Set

class XMLDataGenerator:
    def __init__(self, seed: int = None):
        if seed is not None:
            random.seed(seed)
        self.generated_files = []

    def generate_alternatives(self, n: int) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è n –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤"""
        if n <= 0:
            return []

        # –î–ª—è –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        if n <= 1000:
            return [f"A{i:04d}" for i in range(1, n + 1)]
        else:
            return [f"A{i}" for i in range(1, n + 1)]

    def generate_criteria(self, m: int) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è m –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
        """
        if m <= 0:
            return []

        base_criteria = [
            "–ö–∞—á–µ—Å—Ç–≤–æ", "–°—Ç–æ–∏–º–æ—Å—Ç—å", "–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å", "–£–¥–æ–±—Å—Ç–≤–æ", "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
            "–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–≠–∫–æ–ª–æ–≥–∏—á–Ω–æ—Å—Ç—å", "–°—Ä–æ–∫_—Å–ª—É–∂–±—ã", "–ì–∞—Ä–∞–Ω—Ç–∏—è", "–ü–æ–¥–¥–µ—Ä–∂–∫–∞",
            "–ì–∏–±–∫–æ—Å—Ç—å", "–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å", "–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å", "–ü—Ä–æ—Å—Ç–æ—Ç–∞_–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è",
            "–¢–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∞", "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", "–°–æ–æ–±—â–µ—Å—Ç–≤–æ", "–û–±–Ω–æ–≤–ª–µ–Ω–∏—è", "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è",
            "–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è", "–†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å", "–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å", "–ò–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–æ—Å—Ç—å",
            "–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å", "–°–µ—Ä–≤–∏—Å", "–†–µ–ø—É—Ç–∞—Ü–∏—è", "–û–ø—ã—Ç", "–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è", "–†–µ—Å—É—Ä—Å—ã"
        ]

        if m <= len(base_criteria):
            return base_criteria[:m]
        else:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
            additional = m - len(base_criteria)
            return base_criteria + [f"–ö—Ä–∏—Ç–µ—Ä–∏–π_{i + 30}" for i in range(additional)]

    def generate_expert_names(self, k: int) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        """
        if k <= 0:
            return []

        base_names = ["–ò–≤–∞–Ω–æ–≤", "–ü–µ—Ç—Ä–æ–≤", "–°–∏–¥–æ—Ä–æ–≤", "–ö—É–∑–Ω–µ—Ü–æ–≤", "–°–º–∏—Ä–Ω–æ–≤",
                      "–ü–æ–ø–æ–≤", "–õ–µ–±–µ–¥–µ–≤", "–ö–æ–∑–ª–æ–≤", "–ù–æ–≤–∏–∫–æ–≤", "–ú–æ—Ä–æ–∑–æ–≤",
                      "–í–æ–ª–∫–æ–≤", "–°–æ–ª–æ–≤—å–µ–≤", "–í–∞—Å–∏–ª—å–µ–≤", "–ó–∞–π—Ü–µ–≤", "–ü–∞–≤–ª–æ–≤",
                      "–°–µ–º–µ–Ω–æ–≤", "–ì–æ–ª—É–±–µ–≤", "–í–∏–Ω–æ–≥—Ä–∞–¥–æ–≤", "–ë–æ–≥–¥–∞–Ω–æ–≤", "–í–æ—Ä–æ–±—å–µ–≤",
                      "–§–µ–¥–æ—Ä–æ–≤", "–ú–∏—Ö–∞–π–ª–æ–≤", "–ë–µ–ª—è–µ–≤", "–¢–∞—Ä–∞—Å–æ–≤", "–ë–µ–ª–æ–≤",
                      "–ö–æ–º–∞—Ä–æ–≤", "–û—Ä–ª–æ–≤", "–ö–∏—Å–µ–ª–µ–≤", "–ú–∞–∫–∞—Ä–æ–≤", "–ê–Ω–¥—Ä–µ–µ–≤",
                      "–ù–∏–∫–æ–ª–∞–µ–≤", "–ú–∞–∫—Å–∏–º–æ–≤", "–û—Å–∏–ø–æ–≤", "–ú–∞—Ä–∫–æ–≤", "–ì—É—Å–µ–≤",
                      "–¢–∏—Ç–æ–≤", "–ö—É–∑—å–º–∏–Ω", "–ö—É–¥—Ä—è–≤—Ü–µ–≤", "–ë–∞—Ä–∞–Ω–æ–≤", "–ö—É–ª–∏–∫–æ–≤"]

        if k <= len(base_names):
            return base_names[:k]
        else:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞
            additional = k - len(base_names)
            result = base_names.copy()

            for i in range(additional):
                if i < 100:
                    result.append(f"–≠–∫—Å–ø–µ—Ä—Ç_{i + 41}")
                else:
                    result.append(f"Expert_{i + 1}")

            return result

    def generate_expert_weights(self, k: int,
                                distribution: str = "random") -> List[float]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–µ—Å–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤)
        """
        if k <= 0:
            return []

        if distribution == "equal":
            return [1.0] * k
        elif distribution == "decreasing":
            if k == 1:
                return [1.0]
            weights = [1.0 - i * 0.8 / (k - 1) for i in range(k)]
            return [max(w, 0.1) for w in weights]
        else:  # random (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
            if k == 1:
                return [1.0]

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Å–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏
            weights = []
            for i in range(k):
                if i < k // 3:
                    # –ü–µ—Ä–≤–∞—è —Ç—Ä–µ—Ç—å - –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ –≤–µ—Å–∞
                    weight = random.uniform(0.7, 1.0)
                elif i < 2 * k // 3:
                    # –í—Ç–æ—Ä–∞—è —Ç—Ä–µ—Ç—å - —Å—Ä–µ–¥–Ω–∏–µ –≤–µ—Å–∞
                    weight = random.uniform(0.4, 0.8)
                else:
                    # –ü–æ—Å–ª–µ–¥–Ω—è—è —Ç—Ä–µ—Ç—å - –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–µ –≤–µ—Å–∞
                    weight = random.uniform(0.2, 0.6)

                weights.append(round(weight, 3))

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±—ã–ª 1.0
            max_weight = max(weights)
            if max_weight > 0:
                weights = [round(w / max_weight, 3) for w in weights]

            return weights

    def generate_cpvs(self, criteria: List[str]) -> Dict[str, float]:

        n = len(criteria)

        if n == 0:
            return {}
        if n == 1:
            return {criteria[0]: 1.0}

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        values = []
        for i in range(n):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            if i < n // 3:
                # –ü–µ—Ä–≤–∞—è —Ç—Ä–µ—Ç—å - –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
                value = random.uniform(5, 10)
            elif i < 2 * n // 3:
                # –í—Ç–æ—Ä–∞—è —Ç—Ä–µ—Ç—å - —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
                value = random.uniform(2, 6)
            else:
                # –ü–æ—Å–ª–µ–¥–Ω—è—è —Ç—Ä–µ—Ç—å - –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
                value = random.uniform(1, 3)
            values.append(value)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        total = sum(values)
        cpvs = {}

        for i, criterion in enumerate(criteria):
            cpv = values[i] / total
            # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ 5 –∑–Ω–∞–∫–æ–≤ –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
            cpvs[criterion] = round(cpv, 5)

        return cpvs

    def generate_preferences_for_expert(self, alternatives: List[str],
                                        criteria: List[str]) -> Dict[str, Dict[str, int]]:
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –¥–ª—è –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤
        """
        preferences = {}
        n = len(alternatives)

        if n == 0:
            return {}

        for criterion in criteria:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ –¥–ª—è –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏—è
            shuffled_alts = alternatives.copy()
            random.shuffle(shuffled_alts)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä—É–ø–ø (–æ—Ç 2 –¥–æ min(20, n/3))
            max_groups = min(20, max(2, n // 3))
            min_groups = min(5, max_groups)

            num_groups = random.randint(min_groups, max_groups)

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –ø–æ –≥—Ä—É–ø–ø–∞–º
            groups = []
            remaining_alts = shuffled_alts.copy()

            # –°–æ–∑–¥–∞–µ–º –≥—Ä—É–ø–ø—ã —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
            avg_group_size = max(1, n // num_groups)

            for i in range(num_groups - 1):
                # –†–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã –≤–∞—Ä—å–∏—Ä—É–µ—Ç—Å—è –≤–æ–∫—Ä—É–≥ —Å—Ä–µ–¥–Ω–µ–≥–æ
                min_size = max(1, avg_group_size - 2)
                max_size = min(len(remaining_alts) - (num_groups - i - 1),
                               avg_group_size + 2)

                if max_size < min_size:
                    group_size = min_size
                else:
                    group_size = random.randint(min_size, max_size)

                group = remaining_alts[:group_size]
                groups.append(group)
                remaining_alts = remaining_alts[group_size:]

            # –ü–æ—Å–ª–µ–¥–Ω—è—è –≥—Ä—É–ø–ø–∞ –ø–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
            if remaining_alts:
                groups.append(remaining_alts)

            # –ù–∞–∑–Ω–∞—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –≥—Ä—É–ø–ø–∞–º
            groups_sorted = sorted(groups, key=len, reverse=True)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ
            max_pref = min(15, len(groups_sorted))
            if len(groups_sorted) > 15:
                max_pref = len(groups_sorted)

            criterion_preferences = {}
            used_preferences = set()

            for i, group in enumerate(groups_sorted):
                # –í—ã—á–∏—Å–ª—è–µ–º –±–∞–∑–æ–≤–æ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ
                base_pref = max_pref - i
                if base_pref < 1:
                    base_pref = 1

                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –≤–∞—Ä–∏–∞—Ü–∏—é
                if len(groups_sorted) <= 10:
                    pref = base_pref + random.randint(-1, 1)
                else:
                    pref = base_pref

                pref = max(1, pref)

                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã
                attempts = 0
                while pref in used_preferences and attempts < 5:
                    pref = (pref % max_pref) + 1
                    attempts += 1

                used_preferences.add(pref)

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—É
                group_str = ",".join(sorted(group))
                criterion_preferences[group_str] = pref

            preferences[criterion] = criterion_preferences

        return preferences

    def generate_dataset(self,
                         n_alternatives: int = 50,
                         m_criteria: int = 8,
                         k_experts: int = 12,
                         weight_distribution: str = "random",
                         output_dir: str = "generated_xml") -> Dict:
        print("\n" + "=" * 70)
        print("–ì–ï–ù–ï–†–ê–¶–ò–Ø –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–• –î–ê–ù–ù–´–• –î–õ–Ø DS/AHP-GDM")
        print("=" * 70)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
        n_alternatives = max(1, min(1000, n_alternatives))
        m_criteria = max(1, min(100, m_criteria))
        k_experts = max(1, min(200, k_experts))

        print(f"\n –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:")
        print(f"  ‚Ä¢ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤: {n_alternatives}")
        print(f"  ‚Ä¢ –ö—Ä–∏—Ç–µ—Ä–∏–µ–≤: {m_criteria}")
        print(f"  ‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç–æ–≤: {k_experts}")
        print(f"  ‚Ä¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤: {weight_distribution}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        alternatives = self.generate_alternatives(n_alternatives)
        criteria = self.generate_criteria(m_criteria)
        expert_names = self.generate_expert_names(k_experts)
        expert_weights = self.generate_expert_weights(k_experts, weight_distribution)

        print(f"\n‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –±–∞–∑–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:")
        print(f"  –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã: –ø–µ—Ä–≤—ã–µ 5 - {alternatives[:5]}")
        print(f"  –ö—Ä–∏—Ç–µ—Ä–∏–∏: –ø–µ—Ä–≤—ã–µ 5 - {criteria[:5]}")
        print(f"  –≠–∫—Å–ø–µ—Ä—Ç—ã: –ø–µ—Ä–≤—ã–µ 5 - {expert_names[:5]}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
        experts_data = {}

        print(f"\nüîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤...")

        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        progress_step = max(1, k_experts // 10)

        for i, expert_name in enumerate(expert_names):
            if i % progress_step == 0:
                progress = (i + 1) / k_experts * 100
                print(f"  –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.0f}% ({i + 1}/{k_experts})")

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º CPV
            cpvs = self.generate_cpvs(criteria)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
            preferences = self.generate_preferences_for_expert(alternatives, criteria)

            experts_data[expert_name] = {
                'weight': expert_weights[i],
                'cpvs': cpvs,
                'preferences': preferences
            }

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –Ω–∞–±–æ—Ä
        dataset = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'parameters': {
                    'n_alternatives': n_alternatives,
                    'm_criteria': m_criteria,
                    'k_experts': k_experts,
                    'weight_distribution': weight_distribution,
                    'generator': 'XMLDataGenerator_optimized'
                }
            },
            'alternatives': alternatives,
            'criteria': criteria,
            'experts': experts_data
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ XML
        xml_file = self.save_to_xml(dataset, output_dir)

        return dataset, xml_file

    def save_to_xml(self, dataset: Dict, output_dir: str = "generated_xml") -> str:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        os.makedirs(output_dir, exist_ok=True)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        n_alts = len(dataset['alternatives'])
        n_experts = len(dataset['experts'])
        filename = f"gdm_data_{n_alts}alt_{n_experts}exp_{timestamp}.xml"
        filepath = os.path.join(output_dir, filename)

        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ XML —Ñ–∞–π–ª: {filename}")

        # –°–æ–∑–¥–∞–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π —ç–ª–µ–º–µ–Ω—Ç
        root = ET.Element('ds_ahp_gdm_analysis')

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        comment = ET.Comment(' –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º XMLDataGenerator –¥–ª—è DS/AHP-GDM ')
        root.append(comment)

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = ET.SubElement(root, 'metadata')

        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        alts_elem = ET.SubElement(metadata, 'alternatives')
        alts_elem.text = ','.join(dataset['alternatives'])

        # –ö—Ä–∏—Ç–µ—Ä–∏–∏
        criteria_elem = ET.SubElement(metadata, 'criteria')
        criteria_elem.text = ','.join(dataset['criteria'])

        # –≠–∫—Å–ø–µ—Ä—Ç—ã
        experts_elem = ET.SubElement(metadata, 'experts')
        experts_elem.text = ','.join(dataset['experts'].keys())

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        gen_info = ET.SubElement(metadata, 'generation_info')
        gen_info.set('timestamp', dataset['metadata']['generated_at'])
        gen_info.set('n_alternatives', str(dataset['metadata']['parameters']['n_alternatives']))
        gen_info.set('n_criteria', str(dataset['metadata']['parameters']['m_criteria']))
        gen_info.set('n_experts', str(dataset['metadata']['parameters']['k_experts']))
        gen_info.set('weight_distribution', dataset['metadata']['parameters']['weight_distribution'])
        gen_info.set('generator', dataset['metadata']['parameters']['generator'])

        # –≠–∫—Å–ø–µ—Ä—Ç—ã
        experts_root = ET.SubElement(root, 'experts')

        for expert_name, expert_data in dataset['experts'].items():
            expert_elem = ET.SubElement(experts_root, 'expert')
            expert_elem.set('name', expert_name)
            expert_elem.set('weight', f"{expert_data['weight']:.3f}")

            # CPV
            cpvs_elem = ET.SubElement(expert_elem, 'cpvs')
            for criterion, cpv in expert_data['cpvs'].items():
                criterion_elem = ET.SubElement(cpvs_elem, 'criterion')
                criterion_elem.set('name', criterion)
                criterion_elem.text = f"{cpv:.5f}"

            # –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
            prefs_elem = ET.SubElement(expert_elem, 'preferences')
            for criterion, groups in expert_data['preferences'].items():
                criterion_elem = ET.SubElement(prefs_elem, 'criterion')
                criterion_elem.set('name', criterion)

                for group_str, preference in groups.items():
                    group_elem = ET.SubElement(criterion_elem, 'group')
                    group_elem.set('preference', str(preference))
                    group_elem.text = group_str

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º XML
        xml_string = ET.tostring(root, encoding='unicode', method='xml')

        # –î–æ–±–∞–≤–ª—è–µ–º XML –¥–µ–∫–ª–∞—Ä–∞—Ü–∏—é
        xml_declaration = '<?xml version="1.0" encoding="UTF-8"?>\n'
        full_xml = xml_declaration + xml_string

        dom = minidom.parseString(full_xml)
        pretty_xml = dom.toprettyxml(indent="  ")

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        lines = [line for line in pretty_xml.split('\n') if line.strip()]
        formatted_xml = '\n'.join(lines)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        with open(filepath, 'w', encoding='utf-8', newline='\n') as f:
            f.write(formatted_xml)

        file_size = os.path.getsize(filepath)
        print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath}")
        print(f"üìè –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size:,} –±–∞–π—Ç ({file_size / 1024:.1f} KB)")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.generated_files.append(filepath)

        return filepath


