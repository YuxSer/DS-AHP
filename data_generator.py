import random
from datetime import datetime
from typing import List, Dict, Tuple, Set


class DataGenerator:
    def __init__(self, seed: int = None):
        if seed is not None:
            random.seed(seed)

    def generate_alternatives(self, n: int) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è n –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ —Å –∏–º–µ–Ω–∞–º–∏ A001, A002, ..."""
        return [f"A{i:03d}" for i in range(1, n + 1)]

    def generate_criteria(self, m: int) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è m –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤"""
        base_names = ["–ö–∞—á–µ—Å—Ç–≤–æ", "–°—Ç–æ–∏–º–æ—Å—Ç—å", "–ù–∞–¥—ë–∂–Ω–æ—Å—Ç—å", "–£–¥–æ–±—Å—Ç–≤–æ", "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"]
        if m <= len(base_names):
            return base_names[:m]
        return [f"–ö—Ä–∏—Ç–µ—Ä–∏–π_{i + 1}" for i in range(m)]

    def generate_expert_weights(self, k: int,
                                distribution: str = "uniform") -> Dict[str, float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–µ—Å–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
        experts = {f"E{i + 1}": 1.0 for i in range(k)}

        if distribution == "uniform":
            for name in experts:
                experts[name] = round(random.uniform(0.3, 1.0), 2)
        elif distribution == "decreasing":
            base_weights = [1.0 - i * 0.7 / (k - 1) for i in range(k)]
            for i, name in enumerate(experts.keys()):
                experts[name] = round(base_weights[i], 2)

        return experts

    def generate_cpvs(self, criteria: List[str]) -> Dict[str, float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö CPV —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π —Å—É–º–º—ã=1"""
        cpvs = {c: random.random() for c in criteria}
        total = sum(cpvs.values())
        return {c: round(v / total, 3) for c, v in cpvs.items()}

    def generate_sparse_groups(self, alternatives: List[str],
                               max_groups: int = 30,
                               max_group_size: int = 2) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø (—Ç–æ–ª—å–∫–æ –¥–ª—è 100+ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤)
        –ö–∞–∂–¥–∞—è –≥—Ä—É–ø–ø–∞ - —ç—Ç–æ 1-2 —Å–ª—É—á–∞–π–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        """
        groups = []
        n = len(alternatives)

        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è —É–ø–æ–º–∏–Ω–∞–Ω–∏—è (10-20% –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞)
        mention_count = random.randint(n // 10, n // 5)
        mentioned_alts = random.sample(alternatives, mention_count)

        for _ in range(max_groups):
            # 80% –æ–¥–∏–Ω–æ—á–Ω—ã—Ö, 20% –ø–∞—Ä
            if random.random() < 0.8 or max_group_size < 2:
                # –û–¥–∏–Ω–æ—á–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
                group = [random.choice(mentioned_alts)]
            else:
                # –ü–∞—Ä–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤
                pair = random.sample(mentioned_alts, 2)
                group = sorted(pair)

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—É
            group_str = ",".join(group)
            if group_str not in groups:
                groups.append(group_str)

        return groups

    def generate_preferences(self, groups: List[str]) -> Dict[str, int]:
        """–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –≥—Ä—É–ø–ø–∞–º (—à–∫–∞–ª–∞ 1-7)"""
        preferences = {}
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—ã –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
        sorted_groups = sorted(groups)

        # –ù–∞–∑–Ω–∞—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –æ—Ç –≤—ã—Å–æ–∫–∏—Ö –∫ –Ω–∏–∑–∫–∏–º
        max_pref = 7
        for i, group in enumerate(sorted_groups):
            # –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —Å–Ω–∏–∂–∞—é—Ç—Å—è
            pref = max(1, max_pref - (i % 3))
            preferences[group] = pref

        return preferences

    def generate_dataset(self,
                         n_alternatives: int = 100,
                         m_criteria: int = 3,
                         k_experts: int = 4,
                         max_groups_per_expert: int = 25,
                         max_group_size: int = 2) -> Dict:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö

        Args:
            n_alternatives: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ (100)
            m_criteria: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
            k_experts: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
            max_groups_per_expert: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≥—Ä—É–ø–ø –Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞
            max_group_size: –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã (1 –∏–ª–∏ 2)
        """
        print(f"\n‚ö° –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–ù–ù–´–•: {n_alternatives} –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤")
        print("=" * 60)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
        alternatives = self.generate_alternatives(n_alternatives)
        criteria = self.generate_criteria(m_criteria)
        expert_weights = self.generate_expert_weights(k_experts)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        experts_data = {}
        for expert_name, weight in expert_weights.items():
            cpvs = self.generate_cpvs(criteria)
            preferences = {}

            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫—Ä–∏—Ç–µ—Ä–∏—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—ã
            for criterion in criteria:
                groups = self.generate_sparse_groups(
                    alternatives,
                    max_groups=random.randint(5, max_groups_per_expert // m_criteria),
                    max_group_size=max_group_size
                )

                if groups:
                    preferences[criterion] = self.generate_preferences(groups)

            experts_data[expert_name] = {
                'weight': weight,
                'cpvs': cpvs,
                'preferences': preferences
            }

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –Ω–∞–±–æ—Ä
        dataset = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'parameters': {
                    'n_alternatives': n_alternatives,
                    'm_criteria': m_criteria,
                    'k_experts': k_experts,
                    'max_group_size': max_group_size
                }
            },
            'alternatives': alternatives,
            'criteria': criteria,
            'experts': experts_data
        }

        self.print_summary(dataset)
        return dataset

    def print_summary(self, dataset: Dict):
        print("\nüìä –°–í–û–î–ö–ê:")
        print(f"  –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤: {len(dataset['alternatives'])}")
        print(f"  –ö—Ä–∏—Ç–µ—Ä–∏–µ–≤: {len(dataset['criteria'])}")
        print(f"  –≠–∫—Å–ø–µ—Ä—Ç–æ–≤: {len(dataset['experts'])}")

        # –ü–æ–¥—Å—á–µ—Ç –≥—Ä—É–ø–ø
        total_groups = 0
        mentioned_alts = set()

        for expert_data in dataset['experts'].values():
            for criterion, groups in expert_data['preferences'].items():
                total_groups += len(groups)
                for group_str in groups:
                    for alt in group_str.split(','):
                        mentioned_alts.add(alt.strip())

        print(f"  –í—Å–µ–≥–æ –≥—Ä—É–ø–ø: {total_groups}")
        print(f"  –£–ø–æ–º—è–Ω—É—Ç–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤: {len(mentioned_alts)}/{len(dataset['alternatives'])}")
        print(f"  –ü–æ–∫—Ä—ã—Ç–∏–µ: {len(mentioned_alts) / len(dataset['alternatives']):.1%}")

